{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_train_birdcall_from_image.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-yb2NJ2bd1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVd9Snddn_03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ssBt46rjR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images\"\n",
        "#!unzip birdcall-spectrogram-images.zip > /dev/null\n",
        "#!rm birdcall-spectrogram-images.zip\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images-cut\"\n",
        "#!unzip birdcall-spectrogram-images-cut.zip > /dev/null\n",
        "#!rm -rf birdcall-spectrogram-images-cut.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6UtY0bS9ZrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download \"birdcall-spectrogram-images-cut-multi\"\n",
        "!unzip birdcall-spectrogram-images-cut-multi.zip > /dev/null\n",
        "!rm -rf birdcall-spectrogram-images-cut-multi.zip\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "for directory in Path(\"train_img_2\").iterdir():\n",
        "    if directory.name == \".DS_Store\":\n",
        "        continue\n",
        "    file_paths = [f for f in directory.iterdir() if f.name != \".DS_Store\"]\n",
        "    for path in file_paths:\n",
        "        try:\n",
        "            with open(path, 'rb') as f: img = Image.open(f)\n",
        "        except:\n",
        "            print(path)\n",
        "            !rm {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0syEBFRpwwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam, AdamW\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional\n",
        "import logging\n",
        "from numpy.random import beta\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iknci7vbsjNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "class config:\n",
        "    SEED = 416\n",
        "    N_FOLDS = 5\n",
        "    FOLD = 0\n",
        "    PRETRAINED = True\n",
        "    #TRAIN_INPUT =  \"./train_jpg/\"\n",
        "    #VALID_INPUT =  \"./train_jpg/\"\n",
        "    TRAIN_INPUT = \"./train_img_2\"\n",
        "    VALID_INPUT = \"./train_img_2\"\n",
        "    OUTPUT = \"./drive/My Drive/Study/Bird/output/from_resnet18_28\"\n",
        "    N_LABEL = 264\n",
        "    \n",
        "    TRAIN_BS = 256\n",
        "    VALID_BS = 256\n",
        "    TRAIN_WORKS = 0\n",
        "    VALID_WORKS = 0\n",
        "    \n",
        "    DROPOUT_RATE = 0.2\n",
        "    N_UNIT = 512\n",
        "    EPOCHS = 55\n",
        "    LR = 1e-3\n",
        "    ALPHA = 0.2\n",
        "    T_MAX = 10\n",
        "\n",
        "!mkdir -p \"{config.OUTPUT}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIawPq4_CMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"train_df = pd.read_csv(\"./drive/My Drive/Study/Bird/birdsong-recognition/train.csv\")\n",
        "train_df = train_df[[\"filename\", \"rating\"]]\n",
        "\n",
        "_transform = transforms.Compose([])\n",
        "_datasets = datasets.ImageFolder(root=config.VALID_INPUT, transform=_transform)\n",
        "sound_files = [s[0].split(\"/\")[-1].split(\".\")[0] for s in _datasets.samples]\n",
        "rating_lst = [train_df.query(f\"filename=='{s}.mp3'\")[\"rating\"].iloc[0] for s in tqdm.notebook.tqdm(sound_files)]\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eQgNRKvOz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def get_dataloder():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop((128, 313), pad_if_needed=True, padding_mode=\"constant\"),\n",
        "        transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "        ], p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.RandomApply([\n",
        "            FreqMask(F=30, num_masks=1, replace_with_zero=False),\n",
        "        ], p=0.5), \n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.CenterCrop((128, 313)),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "    train_datasets = datasets.ImageFolder(root=config.TRAIN_INPUT, transform=train_transform)\n",
        "    valid_datasets = datasets.ImageFolder(root=config.VALID_INPUT, transform=valid_transform)\n",
        "\n",
        "    #new_targets = [(t, rating_lst[i]) for i, t in enumerate(valid_datasets.targets)]\n",
        "    #path_lst = [s[0] for s in valid_datasets.samples]\n",
        "    #train_datasets.samples = [(p, t) for p, t in zip(path_lst, new_targets)]\n",
        "    #valid_datasets.samples = [(p, t) for p, t in zip(path_lst, new_targets)]\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
        "    _t = train_datasets.targets\n",
        "    trn_idx, val_idx = [(trn_idx, val_idx) for trn_idx, val_idx in skf.split(_t, _t)][config.FOLD]\n",
        "\n",
        "    train_datasets = torch.utils.data.Subset(train_datasets, trn_idx)\n",
        "    valid_datasets = torch.utils.data.Subset(valid_datasets, val_idx)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.TRAIN_BS, shuffle=True, num_workers=config.TRAIN_WORKS)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.VALID_BS, shuffle=False, num_workers=config.VALID_WORKS)\n",
        "    \n",
        "    return train_data_loader, valid_data_loader\n",
        "\n",
        "data_loader, _ = get_dataloder()\n",
        "#_, data_loader = get_dataloder()\n",
        "for d in data_loader:\n",
        "    break\n",
        "img = d[0][0]\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQREzTLSxDlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(output, target):\n",
        "    #loss = nn.BCEWithLogitsLoss(reduce=False)(output, target)\n",
        "    #loss = loss.mean(1)\n",
        "    #w = y_weight * 0.2\n",
        "    #loss = loss * w\n",
        "    #return loss.mean()\n",
        "    loss = nn.BCEWithLogitsLoss()(output, target)\n",
        "    return loss\n",
        "\n",
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    #W = size[3]\n",
        "    #H = size[2]\n",
        "    #cut_rat = np.sqrt(1. - lam)\n",
        "    #cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    #cy = np.random.randint(H)\n",
        "\n",
        "    #bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    #bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    bby1, bby2 = 0, 313//2\n",
        "    bbx1, bbx2 = 0, 128\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix(input, target, gamma):\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    \n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), gamma)\n",
        "    input[:, :, bbx1:bbx2, bby1:bby2] = input[perm, :, bbx1:bbx2, bby1:bby2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
        "\n",
        "    return input, target.add_(perm_target) # target.mul_(lam).add_(1 - lam, perm_target)\n",
        "\n",
        "\n",
        "def last_layer_mixup(target, gamma):\n",
        "    perm = torch.randperm(target.size(0))\n",
        "    perm_target = target[perm]\n",
        "    return perm, target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "\n",
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        resnet = resnet18(pretrained=config.PRETRAINED)\n",
        "        self.resnet_head = list(resnet.children())\n",
        "        self.resnet_head = nn.Sequential(*self.resnet_head[:-2])\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.dropout = nn.Dropout(p=config.DROPOUT_RATE)\n",
        "        #self.fc = nn.Linear(config.N_UNIT, config.N_LABEL)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(config.N_UNIT, config.N_UNIT), nn.ReLU(), nn.Dropout(p=config.DROPOUT_RATE),\n",
        "            #nn.Linear(config.N_UNIT, config.N_UNIT), nn.ReLU(), nn.Dropout(p=config.DROPOUT_RATE),\n",
        "            nn.Linear(config.N_UNIT, config.N_LABEL))\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):\n",
        "        h = self.resnet_head(x)\n",
        "        if perm is not None:\n",
        "            h = gamma * h + (1 - gamma) * h[perm]\n",
        "        h = self.pool(h)\n",
        "        h = h.view(-1, config.N_UNIT)\n",
        "        h = self.dropout(h)\n",
        "        logits = self.fc(h)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZa1i6wbYyCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(train_data_loader, model, optimizer, scheduler=None):\n",
        "    losses, lrs = [], []\n",
        "    model.train()\n",
        "    t = tqdm.notebook.tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    for (X, y) in t:\n",
        "    \n",
        "        y_true = torch.eye(config.N_LABEL)[y]\n",
        "        #y_true = torch.eye(config.N_LABEL)[y[0]]\n",
        "        #y_weight = y[1]\n",
        "\n",
        "        #_y = y_true\n",
        "        #y_pred = model(X.to(device))\n",
        "\n",
        "        gamma = beta(config.ALPHA, config.ALPHA)\n",
        "\n",
        "        _X, _y = mixup(X, y_true, gamma)\n",
        "\n",
        "        #if np.random.random() >= 0.5:\n",
        "        #    _X, _y = mixup(X, y_true, gamma)\n",
        "        #else:\n",
        "        #    _X, _y = X, y_true\n",
        "        #_X, _y = cutmix(X, y_true, gamma)\n",
        "        \n",
        "        y_pred = model(_X.to(device))\n",
        "\n",
        "        #perm, _y = last_layer_mixup(y_true, gamma)\n",
        "        #y_pred = model(X.to(device), perm, gamma)\n",
        "\n",
        "        #loss = loss_fn(y_pred,  _y.to(device), y_weight.to(device))\n",
        "        loss = loss_fn(y_pred,  _y.to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    \n",
        "    return sum(losses)/len(losses), lrs\n",
        "\n",
        "\n",
        "def get_single_label_from_multi_predict(y, y_pred, threshould):\n",
        "    lst = []\n",
        "    for idx in range(len(y_pred)):\n",
        "        p = y_pred[idx]\n",
        "        if sum(p >= threshould) < 2:\n",
        "            _p = p.argmax().numpy()\n",
        "        else:\n",
        "            _p = np.where(p >= threshould)\n",
        "            _p = _p[0]\n",
        "            if y[idx].numpy() in _p:\n",
        "                _p = y[idx].numpy()\n",
        "            else:\n",
        "                _p = p.argmax().numpy()\n",
        "        lst.append(_p)\n",
        "    return np.array(lst)\n",
        "        \n",
        "def valid_fn(valid_data_loader, model, threshould=0.5):\n",
        "    losses, f1_lst_a, f1_lst_b = [], [], []\n",
        "    model.eval()\n",
        "    t = tqdm.notebook.tqdm(valid_data_loader, total=len(valid_data_loader))\n",
        "    for (X, y) in t:\n",
        "\n",
        "        lst = []\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X.to(device), None, None)\n",
        "            #for idx in range(6):\n",
        "            #    _y_pred = model(X[:,:,:,idx*52:(idx+1)*52].to(device), None, None)\n",
        "            #    lst.append(_y_pred)\n",
        "        #y_pred = sum(lst)\n",
        "\n",
        "        _y = torch.eye(config.N_LABEL)[y]\n",
        "        #_y = torch.eye(config.N_LABEL)[y[0]]\n",
        "\n",
        "        loss = loss_fn(y_pred,  _y.to(device))\n",
        "        #loss = nn.BCEWithLogitsLoss()(y_pred,  _y.to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        y_pred_a = get_single_label_from_multi_predict(y, y_pred.sigmoid().cpu(), threshould)\n",
        "        y_pred_b = y_pred.argmax(1).cpu()\n",
        "\n",
        "        f1_a = f1_score(y, y_pred_a, average=\"micro\")\n",
        "        f1_b = f1_score(y, y_pred_b, average=\"micro\")\n",
        "        f1_lst_a.append(f1_a)\n",
        "        f1_lst_b.append(f1_b)\n",
        "\n",
        "    return sum(f1_lst_a)/len(f1_lst_a), sum(f1_lst_b)/len(f1_lst_b), sum(losses)/len(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNIuATTqY3b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"### Fold-{config.FOLD} ###\")\n",
        "\n",
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=config.LR)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.T_MAX, eta_min=0.0)\n",
        "\n",
        "best_loss, best_score_a, best_score_b = 9999, 0, 0\n",
        "trn_losses, trn_lrs, val_losses, val_scores_a, val_scores_b = [], [], [], [], []\n",
        "for epoch in range(config.EPOCHS):\n",
        "    print(f\"{epoch} epoch\")\n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "    val_f1_a, val_f1_b, vloss = valid_fn(valid_data_loader, model)\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_a <= val_f1_a:\n",
        "        best_score_a = val_f1_a\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_a.bin\")\n",
        "        print(f\"Best Score A Update!!! -> {best_score_a}\")\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_b <= val_f1_b:\n",
        "        best_score_b = val_f1_b\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_b.bin\")\n",
        "        print(f\"Best Score B Update!!! -> {best_score_b}\")\n",
        "\n",
        "    # save best loss model\n",
        "    if best_loss >= vloss:\n",
        "        best_loss = vloss\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_loss.bin\")\n",
        "        print(f\"Best Loss Update!!! -> {best_loss}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\")\n",
        "    torch.save(optimizer.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\")\n",
        "    torch.save(scheduler.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\")\n",
        "\n",
        "    # save training logs\n",
        "    trn_losses.append(tloss)\n",
        "    val_losses.append(vloss)\n",
        "    val_scores_a.append(val_f1_a)\n",
        "    val_scores_b.append(val_f1_b)\n",
        "    trn_lrs.extend(lrs)\n",
        "    log_df = pd.DataFrame(zip(trn_losses, val_losses, val_scores_a, val_scores_b), columns=[\"train loss\", \"valid loss\", \"score_a\", \"score_b\"])\n",
        "    log_df.to_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClZoHVjCbrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Best Score　A: {best_score_a} / Best Score　B: {best_score_b} / Best Loss: {best_loss}\")\n",
        "plt.plot(trn_lrs); plt.show()\n",
        "plt.plot(val_scores_a); plt.show()\n",
        "plt.plot(val_scores_b); plt.show()\n",
        "plt.plot(trn_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JbroaG0qyue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}