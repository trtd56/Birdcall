{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_train_birdcall_from_image.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-yb2NJ2bd1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVd9Snddn_03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6UtY0bS9ZrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images-cut-multi\"\n",
        "#!unzip birdcall-spectrogram-images-cut-multi.zip > /dev/null\n",
        "#!rm -rf birdcall-spectrogram-images-cut-multi.zip\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images-cut\"\n",
        "#!unzip birdcall-spectrogram-images-cut.zip > /dev/null\n",
        "#!rm -rf birdcall-spectrogram-images-cut.zip\n",
        "\n",
        "!kaggle datasets download \"birdcall-spectrogram-images\"\n",
        "!unzip birdcall-spectrogram-images.zip > /dev/null\n",
        "!rm -rf birdcall-spectrogram-images.zip\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images-from-torch\"\n",
        "#!unzip birdcall-spectrogram-images-from-torch.zip > /dev/null\n",
        "#!rm -rf birdcall-spectrogram-images-from-torch.zip\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "#for directory in Path(\"train_img_2\").iterdir():\n",
        "#for directory in Path(\"train_img_4\").iterdir():\n",
        "for directory in Path(\"train_img_5\").iterdir():\n",
        "#for directory in Path(\"train_img_6\").iterdir():\n",
        "    if directory.name == \".DS_Store\":\n",
        "        continue\n",
        "    file_paths = [f for f in directory.iterdir() if f.name != \".DS_Store\"]\n",
        "    for path in file_paths:\n",
        "        try:\n",
        "            with open(path, 'rb') as f: img = Image.open(f)\n",
        "        except:\n",
        "            print(path)\n",
        "            !rm {path}\n",
        "#!cp -r \"./drive/My Drive/Study/Bird/input/cut_image_from_resnet18_12_nocall/0_nocall\" \"train_img_2/\"\n",
        "#!cp -r \"./drive/My Drive/Study/Bird/input/nocall_20200811\" \"train_img_4/0_nocall\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5pkLJB-k52i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install panns-inference\n",
        "#!pip install torchlibrosa\n",
        "#!git clone https://github.com/qiuqiangkong/audioset_tagging_cnn.git\n",
        "#!touch audioset_tagging_cnn/__init__.py\n",
        "#!touch audioset_tagging_cnn/pytorch/__init__.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeKeSV2dxHYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import sys\n",
        "#sys.path.append(\"/content/audioset_tagging_cnn/\")\n",
        "#sys.path.append(\"/content/audioset_tagging_cnn/pytorch\")\n",
        "#from audioset_tagging_cnn.pytorch.models import ResNet22, ResNet38"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0syEBFRpwwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam, AdamW, SGD\n",
        "from torchvision.models import resnet18, resnet50, densenet121\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional\n",
        "import logging\n",
        "from numpy.random import beta\n",
        "#import panns_inference\n",
        "#from panns_inference import SoundEventDetection\n",
        "#from panns_inference.pytorch_utils import interpolate, pad_framewise_output\n",
        "\n",
        "device = torch.device('cuda')\n",
        "#sed = SoundEventDetection(device='cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iknci7vbsjNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "class config:\n",
        "    SEED = 416\n",
        "    N_FOLDS = 5\n",
        "    FOLD = 0\n",
        "    PRETRAINED = True\n",
        "    TRAIN_INPUT = \"./train_img_5\"\n",
        "    VALID_INPUT = \"./train_img_5\"\n",
        "    INITIAL_EPOCH = 0\n",
        "    OUTPUT = \"./drive/My Drive/Study/Bird/output/from_resnet18_49\"\n",
        "    N_LABEL = 264\n",
        "    \n",
        "    TRAIN_BS = 256 #//4\n",
        "    VALID_BS = 256 #//4\n",
        "    TRAIN_WORKS = 0\n",
        "    VALID_WORKS = 0\n",
        "    \n",
        "    DROPOUT_RATE = 0.2\n",
        "    N_UNIT = 512 #*2\n",
        "    EPOCHS = 55\n",
        "    \n",
        "    LR = 1e-3\n",
        "    ALPHA = 0.2\n",
        "    T_MAX = 10\n",
        "\n",
        "    SMOOTH = 0.2\n",
        "\n",
        "!mkdir -p \"{config.OUTPUT}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_b8drXk34HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"train_df = pd.read_csv(\"./drive/My Drive/Study/Bird/birdsong-recognition/train.csv\")\n",
        "#weights = torch.tensor((1/train_df[\"ebird_code\"].value_counts()).reset_index(drop=False).sort_values(\"index\")[\"ebird_code\"].values).to(device)\n",
        "\n",
        "train_df[\"multi_label\"] = train_df.apply(lambda x: [x[\"primary_label\"]] + eval(x[\"secondary_labels\"]) ,axis=1)\n",
        "\n",
        "primary_label2ebird_code = {\n",
        "    df[\"primary_label\"].unique()[0]: ebird_code \n",
        "    for ebird_code, df in train_df[[\"ebird_code\", \"primary_label\"]].groupby(\"ebird_code\")\n",
        "}\n",
        "\n",
        "lst = []\n",
        "for multi_label in train_df[\"multi_label\"]:\n",
        "    _lst = []\n",
        "    for lab in multi_label:\n",
        "        try:\n",
        "            code = primary_label2ebird_code[lab]\n",
        "        except KeyError:\n",
        "            continue\n",
        "        _lst.append(code)\n",
        "    lst.append(_lst)\n",
        "train_df[\"multi_ebird_code\"] = lst\n",
        "\n",
        "keys = set(train_df.ebird_code)\n",
        "values = np.arange(0, len(keys))\n",
        "code_dict = dict(zip(sorted(keys), values))\n",
        "\n",
        "\n",
        "def multi_smooth_label(x):\n",
        "    ebird_code = code_dict[x[\"ebird_code\"]]\n",
        "    multi_ebird_code = list(map(lambda x: code_dict[x], x[\"multi_ebird_code\"]))\n",
        "    t = torch.eye(config.N_LABEL)[ebird_code].numpy()\n",
        "    multi_t = torch.eye(config.N_LABEL)[multi_ebird_code].sum(0).numpy()\n",
        "    return (t * (1-config.SMOOTH) + multi_t * config.SMOOTH).tolist()\n",
        "\n",
        "multi_targets = train_df[[\"ebird_code\", \"multi_ebird_code\"]].apply(multi_smooth_label, axis=1).tolist()\n",
        "multi_targets = list(map(str, multi_targets))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eQgNRKvOz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def get_dataloder():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop((128-35, 313), pad_if_needed=True, padding_mode=\"constant\"),\n",
        "        #transforms.RandomCrop((64, 501), pad_if_needed=True, padding_mode=\"constant\"),\n",
        "        transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "        ], p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.RandomApply([\n",
        "            FreqMask(replace_with_zero=False),\n",
        "        ], p=0.5), \n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.CenterCrop((128-35, 313)),\n",
        "        #transforms.CenterCrop((64, 501)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "    train_datasets = datasets.ImageFolder(root=config.TRAIN_INPUT, transform=train_transform)\n",
        "    valid_datasets = datasets.ImageFolder(root=config.VALID_INPUT, transform=valid_transform)\n",
        "\n",
        "    #train_datasets.samples = [(s[0], t)for s, t in zip(train_datasets.samples, multi_targets)]\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
        "    _t = train_datasets.targets\n",
        "    trn_idx, val_idx = [(trn_idx, val_idx) for trn_idx, val_idx in skf.split(_t, _t)][config.FOLD]\n",
        "\n",
        "    train_datasets = torch.utils.data.Subset(train_datasets, trn_idx)\n",
        "    valid_datasets = torch.utils.data.Subset(valid_datasets, val_idx)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.TRAIN_BS, shuffle=True, num_workers=config.TRAIN_WORKS)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.VALID_BS, shuffle=False, num_workers=config.VALID_WORKS)\n",
        "    \n",
        "    return train_data_loader, valid_data_loader\n",
        "\n",
        "data_loader, _ = get_dataloder()\n",
        "#_, data_loader = get_dataloder()\n",
        "for d in data_loader:\n",
        "    break\n",
        "img = d[0][0]\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQREzTLSxDlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(output, target):\n",
        "    #loss = nn.BCEWithLogitsLoss(pos_weight=weights)(output, target)\n",
        "    loss = nn.BCEWithLogitsLoss()(output, target)\n",
        "    return loss\n",
        "\n",
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "\n",
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        resnet = resnet18(pretrained=config.PRETRAINED)\n",
        "        self.resnet_head = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=config.DROPOUT_RATE)\n",
        "        self.fc = nn.Linear(config.N_UNIT, config.N_LABEL)\n",
        "        #self.fc = AttBlock(config.N_UNIT, config.N_LABEL, activation=\"linear\")\n",
        "\n",
        "        #self.densenet = densenet121(pretrained=config.PRETRAINED)\n",
        "        #self.densenet.classifier = nn.Linear(config.N_UNIT, config.N_LABEL)\n",
        "\n",
        "        #self.sed = nn.Sequential(*list(sed.model.module.children())[4:-1])\n",
        "        #self.ave_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        #self.max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        #self.fc = AttBlock(2048, config.N_LABEL)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.transpose(3, 2)\n",
        "        h = self.resnet_head(x)\n",
        "        h = self.pool(h)\n",
        "        h = h.view(-1, config.N_UNIT)\n",
        "        #h = torch.mean(h, dim=3)\n",
        "\n",
        "        #x1 = F.max_pool1d(h, kernel_size=3, stride=1, padding=1)\n",
        "        #x2 = F.avg_pool1d(h, kernel_size=3, stride=1, padding=1)\n",
        "        #h = x1 + x2\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        logits = self.fc(h)\n",
        "        return {\"clipwise_output\": logits}\n",
        "        #clipwise_output, norm_att, segmentwise_output = self.fc(h)\n",
        "        #segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "        #framewise_output = interpolate(segmentwise_output, 31)\n",
        "        #framewise_output = pad_framewise_output(framewise_output, 313)\n",
        "        #return clipwise_output\n",
        "\n",
        "        #return self.densenet(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZa1i6wbYyCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(train_data_loader, model, optimizer, scheduler=None):\n",
        "    losses, lrs = [], []\n",
        "    model.train()\n",
        "    t = tqdm.notebook.tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    for (X, y) in t:\n",
        "        y_onehot = torch.eye(config.N_LABEL)[y]\n",
        "        #y_onehot = torch.eye(config.N_LABEL+1)[y][:,1:]\n",
        "        #y_onehot = torch.tensor(list(map(eval, y)))\n",
        "\n",
        "        _X, _y = mixup(X, y_onehot, beta(config.ALPHA, config.ALPHA))\n",
        "\n",
        "        #y_pred = model(_X.to(device))\n",
        "        #y_pred = model(_X.to(device)[:,0,:,:].unsqueeze(1))\n",
        "        output = model(_X.to(device))\n",
        "        y_pred = output[\"clipwise_output\"]\n",
        "\n",
        "        loss = loss_fn(y_pred,  _y.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    \n",
        "    return sum(losses)/len(losses), lrs\n",
        "\n",
        "\n",
        "def get_single_label_from_multi_predict(y, y_pred, threshould):\n",
        "    lst = []\n",
        "    for idx in range(len(y_pred)):\n",
        "        p = y_pred[idx]\n",
        "        if sum(p >= threshould) < 2:\n",
        "            _p = p.argmax().numpy()\n",
        "        else:\n",
        "            _p = np.where(p >= threshould)\n",
        "            _p = _p[0]\n",
        "            if y[idx].numpy() in _p:\n",
        "                _p = y[idx].numpy()\n",
        "            else:\n",
        "                _p = p.argmax().numpy()\n",
        "        lst.append(_p)\n",
        "    return np.array(lst)\n",
        "        \n",
        "def valid_fn(valid_data_loader, model, threshould=0.5):\n",
        "    losses, f1_lst_a, f1_lst_b = [], [], []\n",
        "    model.eval()\n",
        "    t = tqdm.notebook.tqdm(valid_data_loader, total=len(valid_data_loader))\n",
        "    for (X, y) in t:\n",
        "\n",
        "        lst = []\n",
        "        with torch.no_grad():\n",
        "            #y_pred = model(X.to(device))\n",
        "            #y_pred = model(X.to(device)[:,0,:,:].unsqueeze(1))\n",
        "            output = model(X.to(device))\n",
        "            y_pred = output[\"clipwise_output\"]\n",
        "\n",
        "        _y = torch.eye(config.N_LABEL)[y]\n",
        "        #_y = torch.eye(config.N_LABEL+1)[y][:,1:]\n",
        "\n",
        "        loss = loss_fn(y_pred,  _y.to(device))\n",
        "        #loss = nn.BCEWithLogitsLoss()(y_pred,  _y.to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        y_pred_a = get_single_label_from_multi_predict(y, y_pred.sigmoid().cpu(), threshould)\n",
        "        #y_pred_a = get_single_label_from_multi_predict(y-1, y_pred.sigmoid().cpu(), threshould)\n",
        "        y_pred_b = y_pred.argmax(1).cpu()\n",
        "\n",
        "        f1_a = f1_score(y, y_pred_a, average=\"micro\")\n",
        "        f1_b = f1_score(y, y_pred_b, average=\"micro\")\n",
        "        #f1_a = f1_score(y-1, y_pred_a, average=\"micro\")\n",
        "        #f1_b = f1_score(y-1, y_pred_b, average=\"micro\")\n",
        "        f1_lst_a.append(f1_a)\n",
        "        f1_lst_b.append(f1_b)\n",
        "\n",
        "    return sum(f1_lst_a)/len(f1_lst_a), sum(f1_lst_b)/len(f1_lst_b), sum(losses)/len(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNIuATTqY3b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"### Fold-{config.FOLD} ###\")\n",
        "\n",
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=config.LR)\n",
        "#optimizer = SGD(model.parameters(), lr=config.LR)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.T_MAX, eta_min=0.0)\n",
        "\n",
        "if config.INITIAL_EPOCH == 0:\n",
        "    best_loss, best_score_a, best_score_b = 9999, 0, 0\n",
        "    trn_losses, trn_lrs, val_losses, val_scores_a, val_scores_b = [], [], [], [], []\n",
        "else:\n",
        "    model.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\"))\n",
        "    optimizer.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\"))\n",
        "    scheduler.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\"))\n",
        "    log_df = pd.read_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\")\n",
        "    _, trn_losses, val_losses, val_scores_a, val_scores_b = log_df.values.T.tolist()\n",
        "    best_loss, best_score_a, best_score_b = min(val_losses), max(val_scores_a), max(val_scores_b)\n",
        "    trn_lrs = []\n",
        "\n",
        "\n",
        "for epoch in range(config.INITIAL_EPOCH, config.EPOCHS):\n",
        "    print(f\"{epoch} epoch\")\n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "    val_f1_a, val_f1_b, vloss = valid_fn(valid_data_loader, model)\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_a <= val_f1_a:\n",
        "        best_score_a = val_f1_a\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_a.bin\")\n",
        "        print(f\"Best Score A Update!!! -> {best_score_a}\")\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_b <= val_f1_b:\n",
        "        best_score_b = val_f1_b\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_b.bin\")\n",
        "        print(f\"Best Score B Update!!! -> {best_score_b}\")\n",
        "\n",
        "    # save best loss model\n",
        "    if best_loss >= vloss:\n",
        "        best_loss = vloss\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_loss.bin\")\n",
        "        print(f\"Best Loss Update!!! -> {best_loss}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\")\n",
        "    torch.save(optimizer.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\")\n",
        "    torch.save(scheduler.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\")\n",
        "\n",
        "    # save training logs\n",
        "    trn_losses.append(tloss)\n",
        "    val_losses.append(vloss)\n",
        "    val_scores_a.append(val_f1_a)\n",
        "    val_scores_b.append(val_f1_b)\n",
        "    trn_lrs.extend(lrs)\n",
        "    log_df = pd.DataFrame(zip(trn_losses, val_losses, val_scores_a, val_scores_b), columns=[\"train loss\", \"valid loss\", \"score_a\", \"score_b\"])\n",
        "    log_df.to_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClZoHVjCbrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Best Score　A: {best_score_a} / Best Score　B: {best_score_b} / Best Loss: {best_loss}\")\n",
        "plt.plot(trn_lrs); plt.show()\n",
        "plt.plot(val_scores_a); plt.show()\n",
        "plt.plot(val_scores_b); plt.show()\n",
        "plt.plot(trn_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMvIJTmY4jf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}