{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_check_train_model.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPTeHUm87fLVpqt+8IsDQmj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uMbjsnz7Q6xO","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUYJMCaLWWz6","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJVj27XBWjte","colab_type":"code","colab":{}},"source":["!pip install -q kaggle\n","!mkdir -p ~/.kaggle\n","!cp \"./drive/My Drive/Study/config/kaggle.json\" ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download \"birdcall-spectrogram-images\"\n","!unzip birdcall-spectrogram-images.zip > /dev/null\n","!rm birdcall-spectrogram-images.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hvl3CWt3WnCs","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","import pandas as pd\n","import os\n","import tqdm\n","import random\n","import time\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam, AdamW\n","from torchvision.models import resnet18\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","from contextlib import contextmanager\n","from typing import Optional\n","import logging\n","from numpy.random import beta\n","\n","device = torch.device('cuda')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCQkv0TXXRcE","colab_type":"code","colab":{}},"source":["class config:\n","    N_LABEL = 264\n","    DROPOUT_RATE = 0.2\n","    N_UNIT = 512\n","    PRETRAINED = False\n","    N_FOLDS = 5\n","    SEED = 416"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWRX8szCumJv","colab_type":"code","colab":{}},"source":["def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n","    # Stack X as [X,X,X]\n","    X = np.stack([X, X, X], axis=-1)\n","\n","    # Standardize\n","    mean = mean or X.mean()\n","    X = X - mean\n","    std = std or X.std()\n","    Xstd = X / (std + eps)\n","    _min, _max = Xstd.min(), Xstd.max()\n","    norm_max = norm_max or _max\n","    norm_min = norm_min or _min\n","    if (_max - _min) > eps:\n","        # Normalize to [0, 255]\n","        V = Xstd\n","        V[V < norm_min] = norm_min\n","        V[V > norm_max] = norm_max\n","        V = 255 * (V - norm_min) / (norm_max - norm_min)\n","        V = V.astype(np.uint8)\n","    else:\n","        # Just zero\n","        V = np.zeros_like(Xstd, dtype=np.uint8)\n","    return V"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EMIZec8WqrI","colab_type":"code","colab":{}},"source":["class BirdcallNet(nn.Module):\n","    def __init__(self):\n","        super(BirdcallNet, self).__init__()\n","        \n","        self.resnet = resnet18(pretrained=config.PRETRAINED)\n","        self.resnet_head = list(self.resnet.children())\n","        self.resnet_head = nn.Sequential(*self.resnet_head[:-1])\n","        \n","        self.dropout = nn.Dropout(p=config.DROPOUT_RATE)\n","        self.fc = nn.Linear(config.N_UNIT, config.N_LABEL)\n","\n","    def forward(self, x):\n","        h = self.resnet_head(x)\n","        h = self.dropout(h.view(-1, config.N_UNIT))\n","        logits = self.fc(h)\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkbxfipYi0zv","colab_type":"code","colab":{}},"source":["\"\"\"train = pd.read_csv(\"./drive/My Drive/Study/Bird/birdsong-recognition/train.csv\")\n","\n","train[\"multi_label\"] = train.apply(lambda x: [x[\"primary_label\"]] + eval(x[\"secondary_labels\"]) ,axis=1)\n","\n","primary_label2ebird_code = {\n","    df[\"primary_label\"].unique()[0]: ebird_code \n","    for ebird_code, df in train[[\"ebird_code\", \"primary_label\"]].groupby(\"ebird_code\")\n","}\n","\n","lst = []\n","for multi_label in train[\"multi_label\"]:\n","    _lst = []\n","    for lab in multi_label:\n","        try:\n","            code = primary_label2ebird_code[lab]\n","        except KeyError:\n","            continue\n","        _lst.append(code)\n","    lst.append(_lst)\n","train[\"multi_ebird_code\"] = lst\n","train[[\"multi_ebird_code\"]].sample(4)\n","\n","model = BirdcallNet()\n","model.load_state_dict(torch.load(f\"./drive/My Drive/Study/Bird/output/from_resnet18_10/birdcallnet_f0_best_loss.bin\", map_location=torch.device('cpu')))\n","model.eval()\n","model.to(device)\n","\n","train_transform = transforms.Compose([transforms.ToTensor(),])\n","train_datasets = datasets.ImageFolder(root=\"./train_jpg/\", transform=train_transform)\n","\n","skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n","\n","_t = train_datasets.targets\n","val_idx = [val_idx for _, val_idx in skf.split(_t, _t)]\n","\n","window = 313\n","\n","for fi, (img, y) in tqdm.notebook.tqdm(enumerate(train_datasets), total=len(train_datasets)):\n","\n","    label = train_datasets.classes[y]\n","    multi_labels = train[\"multi_ebird_code\"].iloc[fi]\n","\n","    if img.shape[2] < window:\n","        pad = torch.zeros((3, 128, window - img.shape[2]))\n","        img = torch.cat([img, pad], dim=2)\n","\n","    lst1, lst2 = [], []\n","    for wi in range(img.shape[2]//window):\n","        _img = img[:,:,wi*window:wi*window+window]\n","        with torch.no_grad():\n","            pred = model(_img.unsqueeze(0).to(device))\n","        lst1.append(pred)\n","        _p = sum(pred.sigmoid()[0] > 0.5)\n","        lst2.append(_p)\n","\n","    multi_target_flag = False\n","    multi_targets = []\n","    if max(lst2) > 1 and len(multi_labels) > 1:\n","        for p1, p2 in zip(lst1, lst2):\n","            if p2 < 2:\n","                continue\n","            _, pred_idx = np.where(p1.cpu() >= 0.5)\n","            multi_target = [train_datasets.classes[i] for i in pred_idx if train_datasets.classes[i] in multi_labels]\n","            if len(multi_target) > 1 and label in multi_target:\n","                multi_target_flag = True\n","                multi_targets.append(multi_target)\n","                break\n","\n","    if multi_target_flag:\n","        if len(multi_targets) > 1:\n","            print(2222)\n","            break\n","        print(111)\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flVgYF4YPdje","colab_type":"code","colab":{}},"source":["models = []\n","for fold in range(config.N_FOLDS):\n","    _m = BirdcallNet()\n","    _m.load_state_dict(torch.load(f\"./drive/My Drive/Study/Bird/output/from_resnet18_12/birdcallnet_f{fold}_best_loss.bin\", map_location=torch.device('cpu')))\n","    _m.to(device)\n","    _m.eval()\n","    models.append(_m)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrZarhAFxyuw","colab_type":"code","colab":{}},"source":["OUTPUT = \"./drive/My Drive/Study/Bird/input/cut_image_from_resnet18_12_nocall\"\n","!mkdir -p \"{OUTPUT}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rufX6lginY9G","colab_type":"code","colab":{}},"source":["\"\"\"lst = []\n","for d in os.listdir(OUTPUT):\n","    for dd in os.listdir(f\"{OUTPUT}/{d}\"):\n","        lst.append(dd)\n","\n","wav_lst = [l.split(\"_\")[0] for l in lst]\n","\n","train_transform = transforms.Compose([transforms.ToTensor(),])\n","train_datasets = datasets.ImageFolder(root=\"./train_jpg/\", transform=train_transform)\n","for fi, d in enumerate(train_datasets.samples):\n","    fnames = train_datasets.imgs[fi][0].split(\"/\")[3].replace(\".jpg\", \"\")\n","    if fnames in wav_lst:\n","        last_idx = fi\n","last_idx\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJq4gtElXP80","colab_type":"code","colab":{}},"source":["train_transform = transforms.Compose([transforms.ToTensor(),])\n","train_datasets = datasets.ImageFolder(root=\"./train_jpg/\", transform=train_transform)\n","\n","skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n","\n","_t = train_datasets.targets\n","val_idx = [val_idx for _, val_idx in skf.split(_t, _t)]\n","\n","window = 313\n","\n","label = \"0_nocall\"\n","!mkdir -p \"{OUTPUT}/{label}\"\n","for fi, (img, y) in tqdm.notebook.tqdm(enumerate(train_datasets), total=len(train_datasets)):\n","\n","    #if fi <= 12500: # 7313, 9841\n","    #    continue\n","\n","    #label = train_datasets.classes[y]\n","    #!mkdir -p \"{OUTPUT}/{label}\"\n","\n","    if img.shape[2]//window <= 2:\n","        continue\n","\n","    if img.shape[2] < window:\n","        pad = torch.zeros((3, 128, window - img.shape[2]))\n","        img = torch.cat([img, pad], dim=2)\n","    \n","    for fold, idxs in enumerate(val_idx):\n","        if fi in idxs:\n","            model = models[fold]\n","            break\n","\n","    lst = []\n","    for wi in range(img.shape[2]//window):\n","        _img = img[:,:,wi*window:wi*window+window]\n","        with torch.no_grad():\n","            pred = model(_img.unsqueeze(0).to(device))\n","        #pred = pred.sigmoid().detach().cpu().numpy()[0][y]\n","        pred = pred.sigmoid().detach().cpu().numpy()[0].max()\n","        lst.append(pred)\n","\n","    #best_wi = np.array(lst).argmax()\n","    #best_img = img[:,:,best_wi*window:best_wi*window+window]\n","    #fname = train_datasets.imgs[fi][0].split(\"/\")[3]\n","    #outpath = f\"{OUTPUT}/{label}/{fname}\"\n","    #cv2.imwrite(outpath, mono_to_color(best_img[0]))\n","\n","    #if max(lst) < 0.5:\n","    #    continue\n","\n","    #good_img_idx = np.where(np.array(lst) >= 0.5)[0]\n","    #for best_wi in good_img_idx:\n","    #    best_img = img[:,:,best_wi*window:best_wi*window+window]\n","    #    fname = train_datasets.imgs[fi][0].split(\"/\")[3].replace(\".jpg\", \"\") + f\"_{best_wi}.jpg\"\n","    #    outpath = f\"{OUTPUT}/{label}/{fname}\"\n","    #    cv2.imwrite(outpath, mono_to_color(best_img[0]))\n","\n","    if min(lst) >= 0.01:\n","        continue\n","    bad_img_idx = np.where(np.array(lst) == min(lst))[0][0]\n","    bad_img = img[:,:,bad_img_idx*window:bad_img_idx*window+window]\n","    fname = train_datasets.imgs[fi][0].split(\"/\")[3].replace(\".jpg\", \"\") + f\"_bad.jpg\"\n","    outpath = f\"{OUTPUT}/{label}/{fname}\"\n","    cv2.imwrite(outpath, mono_to_color(bad_img[0])) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJD0uz3PJz8F","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}