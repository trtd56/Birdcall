{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_train_birdcall_from_image_v2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-yb2NJ2bd1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVd9Snddn_03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6UtY0bS9ZrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "#!kaggle datasets download \"birdcall-spectrogram-images-cut-multi\"\n",
        "#!unzip birdcall-spectrogram-images-cut-multi.zip > /dev/null\n",
        "#!rm -rf birdcall-spectrogram-images-cut-multi.zip\n",
        "#!cp -r \"./drive/My Drive/Study/Bird/input/nocall_20200824\" train_img_2/0_nocall\n",
        "\n",
        "!kaggle datasets download \"birdcall-spectrogram-images\"\n",
        "!unzip birdcall-spectrogram-images.zip > /dev/null\n",
        "!rm -rf birdcall-spectrogram-images.zip\n",
        "\n",
        "!pip install panns-inference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0syEBFRpwwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam, AdamW, SGD\n",
        "from torchvision.models import densenet161\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, CyclicLR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional\n",
        "import logging\n",
        "from numpy.random import beta\n",
        "from PIL import Image\n",
        "\n",
        "from panns_inference.pytorch_utils import interpolate, pad_framewise_output\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iknci7vbsjNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "class config:\n",
        "    SEED = 416\n",
        "    N_FOLDS = 5\n",
        "    FOLD = 0\n",
        "    PRETRAINED = True\n",
        "    INPUT = \"./train_img_8\"\n",
        "    OUTPUT = \"./drive/My Drive/Study/Bird/output/from_densenet161_12\"\n",
        "    N_LABEL = 264\n",
        "    BS = 256//4\n",
        "    WORKS = 0\n",
        "    INITIAL_EPOCH = 21\n",
        "    EPOCHS = 55\n",
        "    ALPHA = 0.2\n",
        "    T_MAX = 10\n",
        "\n",
        "!mkdir -p \"{config.OUTPUT}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eQgNRKvOz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def get_dataloder():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop((128, 313), pad_if_needed=True, padding_mode=\"constant\"),\n",
        "        transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "        ], p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.RandomApply([\n",
        "            FreqMask(replace_with_zero=False),\n",
        "        ], p=0.5), \n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.CenterCrop((128, 313)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "    train_datasets = datasets.ImageFolder(root=config.INPUT, transform=train_transform)\n",
        "    valid_datasets = datasets.ImageFolder(root=config.INPUT, transform=valid_transform)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
        "    _t = train_datasets.targets\n",
        "    trn_idx, val_idx = [(trn_idx, val_idx) for trn_idx, val_idx in skf.split(_t, _t)][config.FOLD]\n",
        "\n",
        "    train_datasets = torch.utils.data.Subset(train_datasets, trn_idx)\n",
        "    valid_datasets = torch.utils.data.Subset(valid_datasets, val_idx)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.BS, shuffle=True, num_workers=config.WORKS)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.BS, shuffle=False, num_workers=config.WORKS)\n",
        "    \n",
        "    return train_data_loader, valid_data_loader\n",
        "\n",
        "data_loader, _ = get_dataloder()\n",
        "for d in data_loader:\n",
        "    break\n",
        "img = d[0][0]\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQREzTLSxDlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logit, target):\n",
        "        target = target.float()\n",
        "        max_val = (-logit).clamp(min=0)\n",
        "        loss = logit - logit * target + max_val + \\\n",
        "               ((-max_val).exp() + (-logit - max_val).exp()).log()\n",
        "\n",
        "        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n",
        "        loss = (invprobs * self.gamma).exp() * loss\n",
        "        if len(loss.size())==2:\n",
        "            loss = loss.sum(dim=1)\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "\n",
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        densenet = densenet161(pretrained=config.PRETRAINED)\n",
        "        self.features = densenet.features\n",
        "\n",
        "        self.l8_a = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n",
        "        #self.l8_b = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n",
        "\n",
        "        self.l8_bs = nn.ModuleList([nn.Conv1d(2208, config.N_LABEL, 1, bias=False) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):\n",
        "        # input: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "        h = self.features(x)  # (batch, unit, time, Hz)\n",
        "\n",
        "        h = F.relu(h, inplace=True)\n",
        "        h  = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        " \n",
        "        xa = self.l8_a(h)  # (batch, n_class, time)\n",
        "        #xb = self.l8_b(h)  # (batch, n_class, time)\n",
        "        #xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        xb_lst = [torch.softmax(l8_b(h), dim=2) for l8_b in self.l8_bs]\n",
        "        xb = torch.stack(xb_lst).sum(0)/3\n",
        "\n",
        "        pseudo_label = (xa.sigmoid() >= 0.5).float()\n",
        "        clipwise_preds = torch.sum(xa * xb, dim=2)\n",
        "        attention_preds = xb\n",
        "\n",
        "        return clipwise_preds, attention_preds, pseudo_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZa1i6wbYyCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(train_data_loader, model, optimizer, scheduler=None):\n",
        "    losses, lrs = [], []\n",
        "    model.train()\n",
        "    t = tqdm.notebook.tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    for (X, y) in t:\n",
        "        y_onehot = torch.eye(config.N_LABEL+1)[y][:, 1:]\n",
        "\n",
        "        b = beta(config.ALPHA, config.ALPHA)\n",
        "        _X, _y = mixup(X, y_onehot, b)\n",
        "\n",
        "        clipwise_preds, attention_preds, pseudo_label = model(_X.to(device))\n",
        "        loss1 = nn.BCEWithLogitsLoss()(clipwise_preds, _y.to(device))\n",
        "        loss2 = nn.BCEWithLogitsLoss()(attention_preds, pseudo_label)\n",
        "        #loss2 = FocalLoss()(attention_preds, pseudo_label)\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    \n",
        "    return sum(losses)/len(losses), lrs\n",
        "\n",
        "\n",
        "def get_single_label_from_multi_predict(y, y_pred, threshould):\n",
        "    lst = []\n",
        "    for idx in range(len(y_pred)):\n",
        "        p = y_pred[idx]\n",
        "        if sum(p >= threshould) < 2:\n",
        "            _p = p.argmax().numpy()\n",
        "        else:\n",
        "            _p = np.where(p >= threshould)\n",
        "            _p = _p[0]\n",
        "            if y[idx].numpy() in _p:\n",
        "                _p = y[idx].numpy()\n",
        "            else:\n",
        "                _p = p.argmax().numpy()\n",
        "        lst.append(_p)\n",
        "    return np.array(lst)\n",
        "\n",
        "\n",
        "def valid_fn(valid_data_loader, model, threshould=0.5):\n",
        "    losses, f1_lst_a, f1_lst_b, mAP_lst = [], [], [], []\n",
        "    model.eval()\n",
        "    t = tqdm.notebook.tqdm(valid_data_loader, total=len(valid_data_loader))\n",
        "    for (X, y) in t:\n",
        "\n",
        "        lst = []\n",
        "        with torch.no_grad():\n",
        "            y_pred, _, _ = model(X.to(device))\n",
        "\n",
        "        _y = torch.eye(config.N_LABEL+1)[y][:, 1:]\n",
        "        loss = nn.BCEWithLogitsLoss()(y_pred, _y.to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        y_pred_a = get_single_label_from_multi_predict(y-1, y_pred.sigmoid().cpu(), threshould)\n",
        "        y_pred_b = y_pred.argmax(1).cpu()\n",
        "\n",
        "        f1_a = f1_score(y-1, y_pred_a, average=\"micro\")\n",
        "        f1_b = f1_score(y-1, y_pred_b, average=\"micro\")\n",
        "        f1_lst_a.append(f1_a)\n",
        "        f1_lst_b.append(f1_b)\n",
        "        mAP_lst.append((y_pred.sigmoid().cpu().numpy(), _y.numpy()))\n",
        "\n",
        "    mAP = average_precision_score(np.vstack([m[1] for m in mAP_lst]), np.vstack([m[0] for m in mAP_lst]), average=None)\n",
        "    mAP = np.nan_to_num(mAP).mean()\n",
        "\n",
        "    return sum(f1_lst_a)/len(f1_lst_a), sum(f1_lst_b)/len(f1_lst_b), sum(losses)/len(losses), mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNIuATTqY3b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"### Fold-{config.FOLD} ###\")\n",
        "\n",
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.T_MAX, eta_min=0.0)\n",
        "\n",
        "if config.INITIAL_EPOCH == 0:\n",
        "    best_loss, best_score_a, best_score_b, best_mAP = 9999, 0, 0, 0\n",
        "    trn_losses, trn_lrs, val_losses, val_scores_a, val_scores_b, mAP_scores = [], [], [], [], [], []\n",
        "else:\n",
        "    model.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\"))\n",
        "    optimizer.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\"))\n",
        "    scheduler.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\"))\n",
        "    log_df = pd.read_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\")\n",
        "    _, trn_losses, val_losses, val_scores_a, val_scores_b, mAP_scores = log_df.values.T.tolist()\n",
        "    best_loss, best_score_a, best_score_b, best_mAP = min(val_losses), max(val_scores_a), max(val_scores_b), max(mAP_scores)\n",
        "    trn_lrs = []\n",
        "\n",
        "for epoch in range(config.INITIAL_EPOCH, config.EPOCHS):\n",
        "    print(f\"{epoch} epoch\")\n",
        "    \n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "    val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, model)\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_a <= val_f1_a:\n",
        "        best_score_a = val_f1_a\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_a.bin\")\n",
        "        print(f\"Best Score A Update!!! -> {best_score_a}\")\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_b <= val_f1_b:\n",
        "        best_score_b = val_f1_b\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_b.bin\")\n",
        "        print(f\"Best Score B Update!!! -> {best_score_b}\")\n",
        "\n",
        "    # save best loss model\n",
        "    if best_loss >= vloss:\n",
        "        best_loss = vloss\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_loss.bin\")\n",
        "        print(f\"Best Loss Update!!! -> {best_loss}\")\n",
        "\n",
        "    # save best mAP model\n",
        "    if best_mAP <= mAP:\n",
        "        best_mAP = mAP\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_mAP.bin\")\n",
        "        print(f\"Best mAP Update!!! -> {best_mAP}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\")\n",
        "    torch.save(optimizer.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\")\n",
        "    torch.save(scheduler.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\")\n",
        "\n",
        "    # save training logs\n",
        "    trn_losses.append(tloss)\n",
        "    val_losses.append(vloss)\n",
        "    val_scores_a.append(val_f1_a)\n",
        "    val_scores_b.append(val_f1_b)\n",
        "    mAP_scores.append(mAP)\n",
        "    trn_lrs.extend(lrs)\n",
        "\n",
        "    log_df = pd.DataFrame(zip(trn_losses, val_losses, val_scores_a, val_scores_b, mAP_scores), columns=[\"train loss\", \"valid loss\", \"score_a\", \"score_b\", \"mAP\"])\n",
        "    log_df.to_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClZoHVjCbrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Best Score　A: {best_score_a} / Best Score　B: {best_score_b} / Best Loss: {best_loss} / Best mAP: {best_mAP}\")\n",
        "plt.plot(trn_lrs); plt.show()\n",
        "plt.plot(val_scores_a); plt.show()\n",
        "plt.plot(val_scores_b); plt.show()\n",
        "plt.plot(trn_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thZbxfU7FPtl",
        "colab_type": "text"
      },
      "source": [
        "## Check Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00KhNhud8EmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
        "    resolution reduction in downsampling of a CNN.\n",
        "\n",
        "    Args:\n",
        "      x: (batch_size, time_steps, classes_num)\n",
        "      ratio: int, ratio to interpolate\n",
        "    Returns:\n",
        "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
        "    \"\"\"\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    return upsampled\n",
        "\n",
        "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
        "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
        "    is the same as the value of the last frame.\n",
        "    Args:\n",
        "      framewise_output: (batch_size, frames_num, classes_num)\n",
        "      frames_num: int, number of frames to pad\n",
        "    Outputs:\n",
        "      output: (batch_size, frames_num, classes_num)\n",
        "    \"\"\"\n",
        "    pad = framewise_output[:, -1:, :].repeat(\n",
        "        1, frames_num - framewise_output.shape[1], 1)\n",
        "    \"\"\"tensor for padding\"\"\"\n",
        "\n",
        "    output = torch.cat((framewise_output, pad), dim=1)\n",
        "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
        "\n",
        "    return output\n",
        "\n",
        "#model = BirdcallNet()\n",
        "#model.to(device)\n",
        "model.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_a.bin\"))\n",
        "for X, y in data_loader:\n",
        "    outout = model(X.to(device))\n",
        "    logits = outout[0].sigmoid().detach().cpu()\n",
        "    seq_preds = outout[1].detach().cpu()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJJ9Uuty77Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2\n",
        "img = X[idx]\n",
        "print(\"target:\", y[idx] - 1, \"/ pred:\", logits[idx].argmax())\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3));plt.show()\n",
        "\n",
        "_seq_preds = seq_preds.transpose(2, 1)\n",
        "_seq_preds = interpolate(_seq_preds, 34)\n",
        "_seq_preds = pad_framewise_output(_seq_preds, 313)\n",
        "_seq_preds = _seq_preds.transpose(2, 1)\n",
        "plt.imshow(_seq_preds[idx], aspect=0.25);plt.show()\n",
        "print(\"target\")\n",
        "plt.plot(seq_preds[idx, y[idx] - 1, :]);plt.show()\n",
        "print(\"predict\")\n",
        "plt.plot(seq_preds[idx, logits[idx].argmax() , :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvwf5cCL7Ogi",
        "colab_type": "text"
      },
      "source": [
        "## SWA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zReF2RD_7RaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "class SWADataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, transform):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        im, t = train_samples[idx]\n",
        "        image = Image.open(im).convert(\"RGB\")\n",
        "        onehot = torch.eye(config.N_LABEL+1)[t][1:]\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image.to(device), onehot.to(device)\n",
        "\n",
        "BEST_MODEL = \"./drive/My Drive/Study/Bird/output/from_densenet161_00\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIJv3iSWKHnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{BEST_MODEL}/birdcallnet_f{config.FOLD}_best_score_a.bin\"))\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "swa_model = AveragedModel(model)\n",
        "#swa_scheduler = SWALR(optimizer, swa_lr=1e-4)\n",
        "#swa_scheduler = SWALR(optimizer, anneal_strategy=\"linear\", anneal_epochs=5, swa_lr=1e-4)\n",
        "\n",
        "#scheduler = None\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=len(train_data_loader)//2, T_mult=1, eta_min=5e-4)\n",
        "\n",
        "\n",
        "trn_losses, trn_lrs, val_log = [], [], []\n",
        "for epoch in range(10):\n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "    swa_model.update_parameters(model)\n",
        "    #swa_scheduler.step()\n",
        "\n",
        "    val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, model)\n",
        "    val_log.append([val_f1_a, val_f1_b, vloss, mAP])\n",
        "    print(f\"{epoch} epoch: score_a={val_f1_a}, score_b={val_f1_b}, valid_loss={vloss}, mAP={mAP}\")\n",
        "\n",
        "    trn_losses.append(tloss)\n",
        "    trn_lrs.extend(lrs)\n",
        "\n",
        "plt.plot(trn_losses);plt.show()\n",
        "plt.plot(trn_lrs);plt.show()\n",
        "display(pd.DataFrame(val_log, columns=[\"val_f1_a\", \"val_f1_b\", \"vloss\", \"mAP\"]))\n",
        "\n",
        "train_samples = [train_data_loader.dataset.dataset.samples[i] for i in train_data_loader.dataset.indices]\n",
        "train_transform = train_data_loader.dataset.dataset.transform\n",
        "\n",
        "swa_dataset = SWADataSet(train_samples, train_transform)\n",
        "swa_data_loader = torch.utils.data.DataLoader(swa_dataset, batch_size=config.BS, shuffle=True, num_workers=config.WORKS)\n",
        "\n",
        "print(\"update bn\")\n",
        "torch.optim.swa_utils.update_bn(swa_data_loader, swa_model)\n",
        "\n",
        "val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, swa_model)\n",
        "print(f\"SWA: score_a={val_f1_a}, score_b={val_f1_b}, valid_loss={vloss}, mAP={mAP}\")\n",
        "\n",
        "torch.save(swa_model.state_dict(), f\"{BEST_MODEL}/birdcallnet_f{config.FOLD}_swa_model_cos_harf_lr.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGCFwRBROyLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}