{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_train_birdcall_from_image_v2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-yb2NJ2bd1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVd9Snddn_03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6UtY0bS9ZrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "!kaggle datasets download \"birdcall-spectrogram-images-cut-multi\"\n",
        "!unzip birdcall-spectrogram-images-cut-multi.zip > /dev/null\n",
        "!rm -rf birdcall-spectrogram-images-cut-multi.zip\n",
        "\n",
        "!pip install panns-inference\n",
        "\n",
        "!cp -r \"./drive/My Drive/Study/Bird/input/nocall_20200824\" train_img_2/0_nocall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0syEBFRpwwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim import Adam, AdamW, SGD\n",
        "from torchvision.models import resnet18, resnet50, densenet121, densenet161\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional\n",
        "import logging\n",
        "from numpy.random import beta\n",
        "\n",
        "from panns_inference.pytorch_utils import interpolate, pad_framewise_output\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iknci7vbsjNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "class config:\n",
        "    SEED = 416\n",
        "    N_FOLDS = 5\n",
        "    FOLD = 0\n",
        "    PRETRAINED = True\n",
        "    INPUT = \"./train_img_2\"\n",
        "    OUTPUT = \"./drive/My Drive/Study/Bird/output/from_resnet18_57\"\n",
        "    N_LABEL = 264\n",
        "    BS = 256//4\n",
        "    WORKS = 0\n",
        "    INITIAL_EPOCH = 0\n",
        "    EPOCHS = 55\n",
        "    ALPHA = 0.2\n",
        "    T_MAX = 10\n",
        "\n",
        "!mkdir -p \"{config.OUTPUT}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eQgNRKvOz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def make_weights_for_balanced_classes(images, nclasses):                        \n",
        "    count = [0] * nclasses                                                      \n",
        "    for item in images:                                                         \n",
        "        count[item[1]] += 1                                                     \n",
        "    weight_per_class = [0.] * nclasses                                      \n",
        "    N = float(sum(count))                                                   \n",
        "    for i in range(nclasses):                                                   \n",
        "        weight_per_class[i] = N/float(count[i])                                 \n",
        "    weight = [0] * len(images)                                              \n",
        "    for idx, val in enumerate(images):                                          \n",
        "        weight[idx] = weight_per_class[val[1]]                                  \n",
        "    return weight  \"\"\"\n",
        "\n",
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def get_dataloder():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop((128, 313), pad_if_needed=True, padding_mode=\"constant\"),\n",
        "        transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "        ], p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.RandomApply([\n",
        "            FreqMask(replace_with_zero=False),\n",
        "        ], p=0.5), \n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.CenterCrop((128, 313)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "    train_datasets = datasets.ImageFolder(root=config.INPUT, transform=train_transform)\n",
        "    valid_datasets = datasets.ImageFolder(root=config.INPUT, transform=valid_transform)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
        "    _t = train_datasets.targets\n",
        "    trn_idx, val_idx = [(trn_idx, val_idx) for trn_idx, val_idx in skf.split(_t, _t)][config.FOLD]\n",
        "\n",
        "    # add sub label\n",
        "    #multi_targets = []\n",
        "    #for v in train[\"multi_ebird_code\"].map(lambda x: [train_datasets.class_to_idx[xx] for xx in x]).values:\n",
        "    #    multi_target = torch.eye(config.N_LABEL)[v].sum(0)\n",
        "    #    multi_targets.append(multi_target)\n",
        "    #train_datasets.samples = [(s[0], torch.cat([torch.tensor([float(s[1])]), multi_targets[i]])) for i, s in enumerate(train_datasets.samples)]\n",
        "    #valid_datasets.samples = [(s[0], torch.cat([torch.tensor([float(s[1])]), multi_targets[i]])) for i, s in enumerate(valid_datasets.samples)]\n",
        "\n",
        "    train_datasets = torch.utils.data.Subset(train_datasets, trn_idx)\n",
        "    valid_datasets = torch.utils.data.Subset(valid_datasets, val_idx)\n",
        "\n",
        "    #weights = make_weights_for_balanced_classes([train_datasets.dataset.imgs[i] for i in trn_idx], config.N_LABEL+1)\n",
        "    #weights = torch.DoubleTensor(weights)                         \n",
        "    #sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))              \n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.BS, shuffle=True, num_workers=config.WORKS)\n",
        "    #train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.BS, sampler=sampler, num_workers=config.WORKS)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.BS, shuffle=False, num_workers=config.WORKS)\n",
        "    \n",
        "    return train_data_loader, valid_data_loader\n",
        "\n",
        "data_loader, _ = get_dataloder()\n",
        "for d in data_loader:\n",
        "    break\n",
        "img = d[0][0]\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQREzTLSxDlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def loss_fn(output, target, onehot):\n",
        "    loss1 = nn.BCEWithLogitsLoss()(output[\"clipwise_output\"], target)\n",
        "    pool, _ = output[\"framewise_output\"].max(1)\n",
        "    #onehot = onehot * (1 - 0.2) + (0.2/config.N_LABEL)\n",
        "    loss2 = nn.BCEWithLogitsLoss()(pool, onehot)\n",
        "    loss = loss1 + loss2*0.5\n",
        "    return loss\"\"\"\n",
        "\n",
        "def loss_fn(output, target):\n",
        "    loss = nn.BCEWithLogitsLoss()(output, target)\n",
        "    return loss\n",
        "\n",
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "def init_layer(layer):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    if hasattr(layer, \"bias\"):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "\n",
        "def init_bn(bn):\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.0)\n",
        "\n",
        "class AttBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_features: int,\n",
        "                 out_features: int,\n",
        "                 activation=\"linear\",\n",
        "                 temperature=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.activation = activation\n",
        "        self.temperature = temperature\n",
        "        self.att = nn.Conv1d(\n",
        "            in_channels=in_features,\n",
        "            out_channels=out_features,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=True)\n",
        "        self.cla = nn.Conv1d(\n",
        "            in_channels=in_features,\n",
        "            out_channels=out_features,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=True)\n",
        "\n",
        "        self.bn_att = nn.BatchNorm1d(out_features)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_layer(self.att)\n",
        "        init_layer(self.cla)\n",
        "        init_bn(self.bn_att)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (n_samples, n_in, n_time)\n",
        "        #norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
        "        norm_att = torch.tanh(self.bn_att(self.att(x)))\n",
        "        norm_att = torch.tanh(norm_att/10)*10\n",
        "        norm_att = torch.softmax(norm_att, dim=-1)\n",
        "\n",
        "        cla = self.nonlinear_transform(self.cla(x))\n",
        "        x = torch.sum(norm_att * cla, dim=2)\n",
        "        return x, norm_att, cla\n",
        "\n",
        "    def nonlinear_transform(self, x):\n",
        "        if self.activation == 'linear':\n",
        "            return x\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return torch.sigmoid(x)\n",
        "\n",
        "class ROI1(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x  = torch.mean(x, dim=3)\n",
        "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x  = x1 + x2\n",
        "        return x\n",
        "\n",
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        densenet = densenet161(pretrained=config.PRETRAINED)\n",
        "        self.features = densenet.features\n",
        "        #self.roi = nn.Sequential(\n",
        "        #    ROI1(),\n",
        "        #    nn.Conv1d(2208, 2208, 1, bias=False),\n",
        "        #    nn.BatchNorm1d(2208),\n",
        "        #    nn.ReLU(inplace=True),\n",
        "        #)\n",
        "        #self.att_block = AttBlock(2208, config.N_LABEL, activation=\"linear\")\n",
        "        #self.fc = nn.Linear(2208, config.N_LABEL)\n",
        "\n",
        "        self.l8_a = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n",
        "        self.l8_b = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n",
        "        #self.bn = nn.BatchNorm1d(config.N_LABEL)\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):\n",
        "        # input: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "        h = self.features(x)  # (batch, unit, time, Hz)\n",
        "        #h = self.roi(h)  # (batch, unit, time)\n",
        "        #h, _ = h.max(2)\n",
        "        #logits = self.fc(h)\n",
        "        #return logits\n",
        "\n",
        "        h = F.relu(h, inplace=True)\n",
        "        h  = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "\n",
        "        xa = self.l8_a(h) #.sigmoid()  # (batch, n_class, time)\n",
        "        xb = self.l8_b(h) #.sigmoid() # (batch, n_class, time)\n",
        "        #xb = self.bn(xb)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        pseudo_label = (xa.sigmoid() >= 0.5).float()\n",
        "        clipwise_preds = torch.sum(xa * xb, dim=2)\n",
        "        attention_preds = xb\n",
        "\n",
        "        return clipwise_preds, attention_preds, pseudo_label\n",
        "\n",
        "        #(clipwise_output, norm_att, segmentwise_output) = self.att_block(h)\n",
        "        # clipwise_output: (batch, n_class)\n",
        "        # segmentwise_output: (batch, n_class, time) \n",
        "        #segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "        #framewise_output = interpolate(segmentwise_output, 32)\n",
        "        #framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
        "        #output_dict = {\n",
        "        #    'framewise_output': framewise_output,\n",
        "        #    'clipwise_output': clipwise_output\n",
        "        #}\n",
        "        #return output_dict\n",
        "\"\"\"\n",
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        self.densenet = densenet161(pretrained=config.PRETRAINED)\n",
        "        self.densenet.classifier = nn.Linear(2208, config.N_LABEL)\n",
        "        #self.densenet.classifier = nn.Sequential(\n",
        "        #                            nn.Linear(2208, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        #                            #nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
        "        #                            nn.Linear(1024, config.N_LABEL))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.densenet(x)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZa1i6wbYyCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(train_data_loader, model, optimizer, scheduler=None):\n",
        "    losses, lrs = [], []\n",
        "    model.train()\n",
        "    t = tqdm.notebook.tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    for (X, y) in t:\n",
        "        #y_onehot = torch.eye(config.N_LABEL)[y[:,0].long()]\n",
        "        y_onehot = torch.eye(config.N_LABEL+1)[y][:, 1:]\n",
        "\n",
        "        b = beta(config.ALPHA, config.ALPHA)\n",
        "        _X, _y = mixup(X, y_onehot, b)\n",
        "        #_, sub_y = mixup(X, y[:,1:], b)\n",
        "\n",
        "        #output_dict = model(_X.to(device))\n",
        "        #loss = loss_fn(output_dict,  _y.to(device), sub_y.to(device))\n",
        "        #output = model(_X.to(device))\n",
        "        #loss = loss_fn(output,  _y.to(device))\n",
        "        clipwise_preds, attention_preds, pseudo_label = model(_X.to(device))\n",
        "        loss1 = nn.BCEWithLogitsLoss()(clipwise_preds, _y.to(device))\n",
        "        loss2 = nn.BCEWithLogitsLoss()(attention_preds, pseudo_label)\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    \n",
        "    return sum(losses)/len(losses), lrs\n",
        "\n",
        "\n",
        "def get_single_label_from_multi_predict(y, y_pred, threshould):\n",
        "    lst = []\n",
        "    for idx in range(len(y_pred)):\n",
        "        p = y_pred[idx]\n",
        "        if sum(p >= threshould) < 2:\n",
        "            _p = p.argmax().numpy()\n",
        "        else:\n",
        "            _p = np.where(p >= threshould)\n",
        "            _p = _p[0]\n",
        "            if y[idx].numpy() in _p:\n",
        "                _p = y[idx].numpy()\n",
        "            else:\n",
        "                _p = p.argmax().numpy()\n",
        "        lst.append(_p)\n",
        "    return np.array(lst)\n",
        "\n",
        "\n",
        "def valid_fn(valid_data_loader, model, threshould=0.5):\n",
        "    losses, f1_lst_a, f1_lst_b, mAP_lst = [], [], [], []\n",
        "    model.eval()\n",
        "    t = tqdm.notebook.tqdm(valid_data_loader, total=len(valid_data_loader))\n",
        "    for (X, y) in t:\n",
        "\n",
        "        lst = []\n",
        "        with torch.no_grad():\n",
        "            #output_dict = model(X.to(device))\n",
        "            #y_pred = model(X.to(device))\n",
        "            y_pred, _, _ = model(X.to(device))\n",
        "\n",
        "        #y_pred = output_dict[\"clipwise_output\"]\n",
        "\n",
        "        #_y = torch.eye(config.N_LABEL)[y[:,0].long()]\n",
        "        #loss = loss_fn(output_dict,  _y.to(device), y[:,1:].to(device))\n",
        "        _y = torch.eye(config.N_LABEL+1)[y][:, 1:]\n",
        "        loss = loss_fn(y_pred, _y.to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        y_pred_a = get_single_label_from_multi_predict(y-1, y_pred.sigmoid().cpu(), threshould)\n",
        "        y_pred_b = y_pred.argmax(1).cpu()\n",
        "\n",
        "        f1_a = f1_score(y-1, y_pred_a, average=\"micro\")\n",
        "        f1_b = f1_score(y-1, y_pred_b, average=\"micro\")\n",
        "        f1_lst_a.append(f1_a)\n",
        "        f1_lst_b.append(f1_b)\n",
        "        mAP_lst.append((y_pred.sigmoid().cpu().numpy(), _y.numpy()))\n",
        "\n",
        "    mAP = average_precision_score(np.vstack([m[1] for m in mAP_lst]), np.vstack([m[0] for m in mAP_lst]), average=None)\n",
        "    mAP = np.nan_to_num(mAP).mean()\n",
        "\n",
        "    return sum(f1_lst_a)/len(f1_lst_a), sum(f1_lst_b)/len(f1_lst_b), sum(losses)/len(losses), mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Syoij_6e_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"print(f\"### Fold-{config.FOLD} ###\")\n",
        "\n",
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "for name, param in model.densenet.named_parameters():\n",
        "    if name.split(\".\")[0] == \"features\":\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "for epoch in range(5):\n",
        "    print(f\"warmup {epoch} epoch\")\n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer)\n",
        "    val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, model)\n",
        "    print(f\"epoch-{epoch}: train loss={tloss}, valid loss={vloss}, score_a={val_f1_a}, score_b={val_f1_b}, mAP={mAP}\")\n",
        "\n",
        "for name, param in model.densenet.named_parameters():\n",
        "    param.requires_grad = True\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNIuATTqY3b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"### Fold-{config.FOLD} ###\")\n",
        "\n",
        "set_seed(config.SEED+config.FOLD)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_dataloder()\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.T_MAX, eta_min=0.0)\n",
        "\n",
        "if config.INITIAL_EPOCH == 0:\n",
        "    best_loss, best_score_a, best_score_b, best_mAP = 9999, 0, 0, 0\n",
        "    trn_losses, trn_lrs, val_losses, val_scores_a, val_scores_b, mAP_scores = [], [], [], [], [], []\n",
        "else:\n",
        "    model.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\"))\n",
        "    optimizer.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\"))\n",
        "    scheduler.load_state_dict(torch.load(f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\"))\n",
        "    log_df = pd.read_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\")\n",
        "    _, trn_losses, val_losses, val_scores_a, val_scores_b, mAP_scores = log_df.values.T.tolist()\n",
        "    best_loss, best_score_a, best_score_b, best_mAP = min(val_losses), max(val_scores_a), max(val_scores_b), max(mAP_scores)\n",
        "    trn_lrs = []\n",
        "\n",
        "for epoch in range(config.INITIAL_EPOCH, config.EPOCHS):\n",
        "    print(f\"{epoch} epoch\")\n",
        "    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "    val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, model)\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_a <= val_f1_a:\n",
        "        best_score_a = val_f1_a\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_a.bin\")\n",
        "        print(f\"Best Score A Update!!! -> {best_score_a}\")\n",
        "\n",
        "    # save best score model\n",
        "    if best_score_b <= val_f1_b:\n",
        "        best_score_b = val_f1_b\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_score_b.bin\")\n",
        "        print(f\"Best Score B Update!!! -> {best_score_b}\")\n",
        "\n",
        "    # save best loss model\n",
        "    if best_loss >= vloss:\n",
        "        best_loss = vloss\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_loss.bin\")\n",
        "        print(f\"Best Loss Update!!! -> {best_loss}\")\n",
        "\n",
        "    # save best mAP model\n",
        "    if best_mAP <= mAP:\n",
        "        best_mAP = mAP\n",
        "        torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_best_mAP.bin\")\n",
        "        print(f\"Best mAP Update!!! -> {best_mAP}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_model.bin\")\n",
        "    torch.save(optimizer.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_optimizer.bin\")\n",
        "    torch.save(scheduler.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_latest_scheduler.bin\")\n",
        "\n",
        "    # save training logs\n",
        "    trn_losses.append(tloss)\n",
        "    val_losses.append(vloss)\n",
        "    val_scores_a.append(val_f1_a)\n",
        "    val_scores_b.append(val_f1_b)\n",
        "    mAP_scores.append(mAP)\n",
        "    trn_lrs.extend(lrs)\n",
        "\n",
        "    log_df = pd.DataFrame(zip(trn_losses, val_losses, val_scores_a, val_scores_b, mAP_scores), columns=[\"train loss\", \"valid loss\", \"score_a\", \"score_b\", \"mAP\"])\n",
        "    log_df.to_csv(f\"{config.OUTPUT}/valid_f1_fold{config.FOLD}_score.csv\", index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClZoHVjCbrsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Best Score　A: {best_score_a} / Best Score　B: {best_score_b} / Best Loss: {best_loss} / Best mAP: {best_mAP}\")\n",
        "plt.plot(trn_lrs); plt.show()\n",
        "plt.plot(val_scores_a); plt.show()\n",
        "plt.plot(val_scores_b); plt.show()\n",
        "plt.plot(trn_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDitYyvWKur1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for X, y in data_loader:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y66GKwC272iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outout = model(X.to(device))\n",
        "logits = outout[0].sigmoid().detach()\n",
        "seq_preds = outout[1].detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJJ9Uuty77Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 4\n",
        "img = X[idx]\n",
        "print(\"target:\", y[idx] - 1, \"/ pred:\", logits[idx].cpu().argmax())\n",
        "plt.imshow(np.rollaxis(img.numpy(), 0, 3));plt.show()\n",
        "plt.plot(seq_preds.cpu()[idx, y[idx] - 1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00KhNhud8EmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18UTcA8c8QAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}