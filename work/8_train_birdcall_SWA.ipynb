{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_train_birdcall_SWA.ipynb","provenance":[{"file_id":"1ydR5tMkO3lw_op2go4T4wHbEYRl6V3Bs","timestamp":1599557380961},{"file_id":"1V_aK_gAqlkvLFQ2kKEe9GRhFOYipyqHt","timestamp":1597645757706}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"w-yb2NJ2bd1U","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVd9Snddn_03","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6UtY0bS9ZrL","colab_type":"code","colab":{}},"source":["!pip install -q kaggle\n","!mkdir -p .kaggle\n","!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n","!chmod 600 .kaggle/kaggle.json\n","!mv .kaggle /root\n","\n","!kaggle datasets download \"birdcall-spectrogram-images\"\n","!unzip birdcall-spectrogram-images.zip > /dev/null\n","!rm -rf birdcall-spectrogram-images.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0syEBFRpwwLb","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import tqdm\n","import random\n","import time\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.optim import Adam, AdamW, SGD\n","from torchvision.models import densenet161\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, CyclicLR\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import f1_score, average_precision_score\n","from sklearn.model_selection import StratifiedKFold\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","\n","from contextlib import contextmanager\n","from typing import Optional\n","import logging\n","from numpy.random import beta\n","from PIL import Image\n","\n","device = torch.device('cuda')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2eQgNRKvOz1","colab_type":"code","colab":{}},"source":["class FreqMask:\n","    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n","        self.F = F\n","        self.num_masks = num_masks\n","        self.replace_with_zero = replace_with_zero\n","\n","    def __call__(self, spec):\n","        cloned = spec.clone()\n","        num_mel_channels = cloned.shape[1]\n","    \n","        for i in range(0, self.num_masks):        \n","            f = random.randrange(0, self.F)\n","            f_zero = random.randrange(0, num_mel_channels - f)\n","\n","            # avoids randrange error if values are equal and range is empty\n","            if (f_zero == f_zero + f): return cloned\n","\n","            mask_end = random.randrange(f_zero, f_zero + f) \n","            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n","            else: cloned[:, f_zero:mask_end] = cloned.mean()\n","    \n","        return cloned\n","\n","def get_dataloder():\n","    train_transform = transforms.Compose([\n","        transforms.RandomCrop((128, 313), pad_if_needed=True, padding_mode=\"constant\"),\n","        transforms.RandomApply([\n","            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n","        ], p=0.5),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","        transforms.RandomApply([\n","            FreqMask(replace_with_zero=False),\n","        ], p=0.5), \n","    ])\n","    valid_transform = transforms.Compose([\n","        transforms.CenterCrop((128, 313)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ])\n","\n","    train_datasets = datasets.ImageFolder(root=config.INPUT, transform=train_transform)\n","    valid_datasets = datasets.ImageFolder(root=config.INPUT, transform=valid_transform)\n","\n","    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n","    _t = train_datasets.targets\n","    trn_idx, val_idx = [(trn_idx, val_idx) for trn_idx, val_idx in skf.split(_t, _t)][config.FOLD]\n","\n","    train_datasets = torch.utils.data.Subset(train_datasets, trn_idx)\n","    valid_datasets = torch.utils.data.Subset(valid_datasets, val_idx)\n","\n","    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.BS, shuffle=True, num_workers=config.WORKS)\n","    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.BS, shuffle=False, num_workers=config.WORKS)\n","    \n","    return train_data_loader, valid_data_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQREzTLSxDlv","colab_type":"code","colab":{}},"source":["def mixup(input, target, gamma):\n","    # target is onehot format!\n","    perm = torch.randperm(input.size(0))\n","    perm_input = input[perm]\n","    perm_target = target[perm]\n","    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n","\n","\n","class BirdcallNet(nn.Module):\n","    def __init__(self):\n","        super(BirdcallNet, self).__init__()\n","        densenet = densenet161(pretrained=config.PRETRAINED)\n","        self.features = densenet.features\n","\n","        self.l8_a = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n","        self.l8_b = nn.Conv1d(2208, config.N_LABEL, 1, bias=False)\n","\n","    def forward(self, x, perm=None, gamma=None):\n","        # input: (batch, channel, Hz, time)\n","        frames_num = x.shape[3]\n","        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n","        h = self.features(x)  # (batch, unit, time, Hz)\n","\n","        h = F.relu(h, inplace=True)\n","        h  = torch.mean(h, dim=3)  # (batch, unit, time)\n"," \n","        xa = self.l8_a(h)  # (batch, n_class, time)\n","        xb = self.l8_b(h)  # (batch, n_class, time)\n","        xb = torch.softmax(xb, dim=2)\n","\n","        pseudo_label = (xa.sigmoid() >= 0.5).float()\n","        clipwise_preds = torch.sum(xa * xb, dim=2)\n","        attention_preds = xb\n","\n","        return clipwise_preds, attention_preds, pseudo_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZa1i6wbYyCm","colab_type":"code","colab":{}},"source":["def train_fn(train_data_loader, model, optimizer, scheduler=None):\n","    losses, lrs = [], []\n","    model.train()\n","    t = tqdm.notebook.tqdm(train_data_loader, total=len(train_data_loader))\n","    for (X, y) in t:\n","        y_onehot = torch.eye(config.N_LABEL+1)[y][:, 1:]\n","\n","        b = beta(config.ALPHA, config.ALPHA)\n","        _X, _y = mixup(X, y_onehot, b)\n","\n","        clipwise_preds, attention_preds, pseudo_label = model(_X.to(device))\n","        loss1 = nn.BCEWithLogitsLoss()(clipwise_preds, _y.to(device))\n","        loss2 = nn.BCEWithLogitsLoss()(attention_preds, pseudo_label)\n","        loss = loss1 + loss2\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        losses.append(loss.item())\n","        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n","    \n","    return sum(losses)/len(losses), lrs\n","\n","\n","def get_single_label_from_multi_predict(y, y_pred, threshould):\n","    lst = []\n","    for idx in range(len(y_pred)):\n","        p = y_pred[idx]\n","        if sum(p >= threshould) < 2:\n","            _p = p.argmax().numpy()\n","        else:\n","            _p = np.where(p >= threshould)\n","            _p = _p[0]\n","            if y[idx].numpy() in _p:\n","                _p = y[idx].numpy()\n","            else:\n","                _p = p.argmax().numpy()\n","        lst.append(_p)\n","    return np.array(lst)\n","\n","\n","def valid_fn(valid_data_loader, model, threshould=0.5):\n","    losses, f1_lst_a, f1_lst_b, mAP_lst = [], [], [], []\n","    model.eval()\n","    t = tqdm.notebook.tqdm(valid_data_loader, total=len(valid_data_loader))\n","    for (X, y) in t:\n","\n","        lst = []\n","        with torch.no_grad():\n","            y_pred, _, _ = model(X.to(device))\n","\n","        _y = torch.eye(config.N_LABEL+1)[y][:, 1:]\n","        loss = nn.BCEWithLogitsLoss()(y_pred, _y.to(device))\n","        losses.append(loss.item())\n","\n","        y_pred_a = get_single_label_from_multi_predict(y-1, y_pred.sigmoid().cpu(), threshould)\n","        y_pred_b = y_pred.argmax(1).cpu()\n","\n","        f1_a = f1_score(y-1, y_pred_a, average=\"micro\")\n","        f1_b = f1_score(y-1, y_pred_b, average=\"micro\")\n","        f1_lst_a.append(f1_a)\n","        f1_lst_b.append(f1_b)\n","        mAP_lst.append((y_pred.sigmoid().cpu().numpy(), _y.numpy()))\n","\n","    mAP = average_precision_score(np.vstack([m[1] for m in mAP_lst]), np.vstack([m[0] for m in mAP_lst]), average=None)\n","    mAP = np.nan_to_num(mAP).mean()\n","\n","    return sum(f1_lst_a)/len(f1_lst_a), sum(f1_lst_b)/len(f1_lst_b), sum(losses)/len(losses), mAP"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mvwf5cCL7Ogi","colab_type":"text"},"source":["## SWA"]},{"cell_type":"code","metadata":{"id":"zReF2RD_7RaO","colab_type":"code","colab":{}},"source":["class SWADataSet(torch.utils.data.Dataset):\n","    def __init__(self, samples, transform):\n","        self.samples = samples\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        im, t = train_samples[idx]\n","        image = Image.open(im).convert(\"RGB\")\n","        onehot = torch.eye(config.N_LABEL+1)[t][1:]\n","        tensor_image = self.transform(image)\n","        return tensor_image.to(device), onehot.to(device)\n","\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGbpBhLnQiNH","colab_type":"code","colab":{}},"source":["class config:\n","    SEED = 416\n","    N_FOLDS = 5\n","    FOLD = 0\n","    PRETRAINED = True\n","    INPUT = \"./train_img_8\"\n","    OUTPUT = \"./drive/My Drive/Study/Bird/output/from_densenet161_13\"\n","    BEST_MODEL = \"./drive/My Drive/Study/Bird/output/from_densenet161_11\"\n","    N_LABEL = 264\n","    BS = 256//4\n","    WORKS = 0\n","    ALPHA = 0.2\n","    T_MAX = 10\n","\n","!mkdir -p \"{config.OUTPUT}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIJv3iSWKHnj","colab_type":"code","colab":{}},"source":["set_seed(config.SEED+config.FOLD)\n","\n","train_data_loader, valid_data_loader = get_dataloder()\n","model = BirdcallNet()\n","model.to(device)\n","model.load_state_dict(torch.load(f\"{config.BEST_MODEL}/birdcallnet_f{config.FOLD}_best_score_a.bin\"))\n","#model.load_state_dict(torch.load(f\"{config.BEST_MODEL}/birdcallnet_f{config.FOLD}_best_loss.bin\"))\n","\n","#optimizer = SGD(model.parameters(), lr=1e-2)\n","optimizer = Adam(model.parameters(), lr=1e-2)\n","\n","swa_model = AveragedModel(model)\n","#swa_scheduler = SWALR(optimizer, swa_lr=1e-4)\n","#swa_scheduler = SWALR(optimizer, anneal_strategy=\"linear\", anneal_epochs=5, swa_lr=1e-4)\n","\n","#scheduler = None\n","scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=len(train_data_loader)//2, T_mult=1, eta_min=1e-3)\n","\n","\n","trn_losses, trn_lrs, val_log = [], [], []\n","for epoch in range(10):\n","    tloss, lrs = train_fn(train_data_loader, model, optimizer, scheduler)\n","    swa_model.update_parameters(model)\n","    #swa_scheduler.step()\n","\n","    val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, model)\n","    val_log.append([val_f1_a, val_f1_b, vloss, mAP])\n","    print(f\"{epoch} epoch: score_a={val_f1_a}, score_b={val_f1_b}, valid_loss={vloss}, mAP={mAP}\")\n","\n","    trn_losses.append(tloss)\n","    trn_lrs.extend(lrs)\n","\n","plt.plot(trn_losses);plt.show()\n","plt.plot(trn_lrs);plt.show()\n","display(pd.DataFrame(val_log, columns=[\"val_f1_a\", \"val_f1_b\", \"vloss\", \"mAP\"]))\n","\n","train_samples = [train_data_loader.dataset.dataset.samples[i] for i in train_data_loader.dataset.indices]\n","train_transform = train_data_loader.dataset.dataset.transform\n","\n","swa_dataset = SWADataSet(train_samples, train_transform)\n","swa_data_loader = torch.utils.data.DataLoader(swa_dataset, batch_size=config.BS, shuffle=True, num_workers=config.WORKS)\n","\n","print(\"update bn\")\n","torch.optim.swa_utils.update_bn(swa_data_loader, swa_model)\n","\n","val_f1_a, val_f1_b, vloss, mAP = valid_fn(valid_data_loader, swa_model)\n","print(f\"SWA: score_a={val_f1_a}, score_b={val_f1_b}, valid_loss={vloss}, mAP={mAP}\")\n","\n","torch.save(swa_model.state_dict(), f\"{config.OUTPUT}/birdcallnet_f{config.FOLD}_swa.bin\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGCFwRBROyLb","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}